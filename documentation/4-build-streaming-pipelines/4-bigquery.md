# ğŸ§  Module â€” BigQuery: The Analytical Engine (Streaming analytics, Continuous Queries, Performance, Lab)

At this point in the pipeline, Pub/Sub (or Kafka) is your **front door**, Dataflow is your **processing brain**, and BigQuery becomes your **analytical engine**â€”the place where you answer questions at scale using SQL, even when the query pattern is not known in advance.

BigQuery is the right fit when:

* you need to run **ad-hoc SQL** on large datasets,
* you want **fast analytics** (seconds over TB/PB),
* you care about **cost control** via scan reduction (partitioning/clustering),
* and you want to operationalise results (Reverse ETL, continuous queries).

---

## 1) Why BigQuery sits here in the streaming journey

### The â€œafter Dataflowâ€ question

Once Dataflow has parsed/enriched/aggregated, you need somewhere that can:

* store huge amounts of data cheaply,
* run SQL quickly,
* support many analysts and dashboards,
* and scale without you managing infrastructure.

BigQuery does that because itâ€™s:

* **serverless**
* **massively parallel**
* **columnar** (optimised for analytics, not point lookups)
* capable of querying **petabytes** of prepared streaming data fast.

In the Grand Prix context, BigQuery answers questions like:

* â€œWhich drivers have consistent lap times?â€
* â€œCorrelation between gear changes and incidents?â€
* â€œWeather effect on outcomes?â€

Those are *analytics questions*, not serving questions (thatâ€™s Bigtable territory).

---

## 2) BigQuery ingestion: Batch vs Streaming (and the exam decision rule)

### Batch ingest

**When:** freshness isnâ€™t critical (hourly/daily), big bounded loads.
**How:** load in chunks.
**Tools:** BigQuery load jobs, Data Transfer Service (DTS), Spark/Hadoop connectors.
**Trade-off:** cheap/scalable, but you accept latency.

### Streaming ingest

**When:** dashboards, anomaly detection, operational analytics need data within seconds.
**How:** row-by-row or micro-batches.
**Tools:** Storage Write API, Pub/Sub â†’ BigQuery subscription, Dataflow.
**Trade-off:** more expensive per GiB, but low latency.

**High-yield exam rule:**

* If the requirement screams **â€œwithin secondsâ€ / real-time dashboardsâ€** â†’ streaming ingest.
* If it says **â€œnightly loads / historical logs / cost minimisationâ€** â†’ batch ingest.

---

## 3) ETL vs ELT: why BigQuery shifts the default

### Traditional ETL

Transform before loading into the warehouse:

* Dataflow / Spark does transformations
* BigQuery stores final shaped data

### Modern ELT with BigQuery

Load raw data *first* into BigQuery, then transform **in-place using SQL**.

Why BigQuery pushes ELT:

1. simplifies pipeline (less external processing for many cases),
2. BigQuery compute is powerful and serverless,
3. keeps raw data â†’ re-run transformations later without re-ingesting.

**Practical meaning:**

* For many transformations, you can skip Dataflow entirely and use BigQuery SQL (especially batch ELT).
* For **stateful streaming** and messy event-time problems, Dataflow still wins.

---

## 4) Storage Write API (why they mention it)

For streaming ingestion, the **BigQuery Storage Write API** is presented as the preferred modern mechanism (high throughput, fewer legacy limitations).

**What you should take away:**

* â€œLegacy insert API has row/throughput constraints.â€
* â€œStorage Write API is the preferred choice for new streaming ingestion.â€

Exam-style trigger:

* If they ask â€œbest way to ingest high-throughput streaming into BigQueryâ€ â†’ Storage Write API patterns.

---

## 5) DTS (Data Transfer Service): what it is *and what it is not*

**DTS is NOT streaming.**
Itâ€™s scheduled batch transfers, â€œset it and forget itâ€.

Use it when:

* you need recurring pulls from supported sources,
* like Ads/YouTube or cloud storage (including S3) on a schedule.

If the question says â€œscheduled import every day/hour from a supported SaaS/sourceâ€ â†’ DTS.

---

## 6) Change Data Capture (CDC): the â€œnear-real-time database mirrorâ€ pattern

CDC is used when you want **a near-instant reflection of a databaseâ€™s changes** in BigQuery:

* inserts
* updates
* deletes

**Core idea:** you stream *changes*, not full reloads.

**Exam cue:** If they say â€œmirror production DB changes in BigQuery, including deletesâ€ â†’ CDC design pattern.

And the module is very clear about the boundary:

* CDC keeps tables current,
* but **complex transformations/stateful logic** still points you to **Dataflow**.

---

## 7) Dataflow vs BigQuery Continuous Queries (super important distinction)

### Dataflow

Beam pipelines, sophisticated intermediary:

* handles complex transforms
* windowing/watermarks/state
* can write dynamically to multiple tables or other sinks

### BigQuery Continuous Queries

Long-running SQL that processes new rows as they arrive in a source table and writes results to:

* another BigQuery table
* Pub/Sub topic
* Bigtable table
* Spanner table

Theyâ€™re positioned as:

> â€œa lightweight, SQL-native ETL tool inside BigQueryâ€

**But with two key constraints you must remember (theyâ€™re exam bait):**

1. **Continuous queries require BigQuery reservations** (slots).
2. Theyâ€™re designed to be **stateless**.

So the decision rule is:

* Need **stateful streaming semantics** (late data refinement, session windows, complex joins, event-time correctness)? â†’ **Dataflow**
* Need **simple real-time transformations/filters/derivations** expressed in SQL, low engineering overhead, and you can live with statelessness? â†’ **Continuous queries**

---

## 8) Reverse ETL (BigQuery â†’ operational systems)

Reverse ETL = push analytics results back into systems that *run the business*.

In this module, they connect reverse ETL strongly with continuous queries:

Workflow:

1. Write SQL
2. Run continuously
3. Output is continuously pushed to destinations like:

    * Pub/Sub (trigger apps)
    * Bigtable (serve state)
    * Spanner (serve app users without hammering BigQuery)
    * other BigQuery tables (pipeline chaining)

**Exam cue:** If data starts in BigQuery and ends up powering apps/CRM/alerts â†’ reverse ETL.

---

## 9) Continuous queries + â€œagentic AIâ€ demo (what they want you to learn)

The security demo isnâ€™t about details; itâ€™s about recognising a new architectural pattern:

* streaming events land in BigQuery
* a continuous query identifies something interesting
* it triggers an agent workflow (ADK) using LLM prompts
* results get logged back to BigQuery for audit + feedback loops

Takeaway for exam thinking:

* BigQuery isnâ€™t only â€œwarehouseâ€; it can be **event-driven** when paired with continuous execution outputs.

---

## 10) Performance design: columnar storage, partitioning, clustering

### Columnar storage (why itâ€™s fast for analytics)

BigQuery stores columns separately, so analytical queries that scan a few columns can avoid reading everything.

### Partitioning

Splits a table into chunks (often by date/timestamp).
Main goal: **prune partitions** â†’ scan less data â†’ cheaper and faster.

### Clustering

Organises data *within partitions* by chosen columns to reduce scan inside partitions (better pruning for common filters/group-bys).

**Key clarification (directly tied to the review question):**

* Partitioning = segment by time (or int range) into partitions
* Clustering = co-locate similar values for faster pruning/filtering within partitions
  It is **not** â€œsegment data by dateâ€â€”thatâ€™s partitioning.

So the review statement:

> â€œThe primary purpose of clustering is to segment by date/timestamp column to prune partitionsâ€

âœ… **False** (thatâ€™s partitioning, not clustering)

---

## 11) Enforcing cost control: require partition filter (high-yield exam item)

If you have a partitioned table and want to **force queries to filter on the partition column**, the most direct enforcement is:

âœ… **Table-level partition filter enforcement** using the table property `--require_partition_filter`

Why this is the correct one:

* Itâ€™s enforced at the **table level**
* queries fail if they donâ€™t include the filter
* prevents accidental full scans

Why the others are weaker:

* views are bypassable if users can access the base table
* IAM doesnâ€™t inspect SQL query content
* reservations control compute capacity, not query predicates

---

# ğŸ§ª Lab: Stream e-sports data with Pub/Sub â†’ BigQuery (no Dataflow)

This lab is intentionally â€œlighterâ€ than the Dataflow lab. It demonstrates the idea:

> â€œWhat if I want real-time ingestion and analytics using mostly configuration + SQL?â€

### What you build

1. **BigQuery dataset + table** (`esports_analytics.raw_events`) with a defined schema
2. **Pub/Sub topic + subscription**
3. Configure subscription delivery type: **Write to BigQuery**
4. Fix IAM so Pub/Sub can write to BigQuery
5. Run Python simulator to publish events
6. Query raw table + build leaderboard views in SQL

### The two IAM â€œgotchasâ€ they want burned into your brain

#### Gotcha A: Pub/Sub service account needs BigQuery permissions

When you switch subscription delivery to â€œWrite to BigQueryâ€, Pub/Sub uses a Google-managed service account like:

`service-<PROJECT_NUMBER>@gcp-sa-pubsub.iam.gserviceaccount.com`

You must grant it dataset/table permissions (they use **BigQuery Data Editor** at the dataset level in the lab).

**Exam cue:** â€œSubscription canâ€™t write to BigQuery; missing bigquery.tables.updateDataâ€ â†’ fix IAM for Pub/Sub SA.

#### Gotcha B: Your compute service account needs Pub/Sub Publisher

Your simulator (running under the compute principal) must be able to publish to the topic.

**Exam cue:** â€œPermission denied publishing to topicâ€ â†’ grant **Pub/Sub Publisher** to the compute service account.

---

## 12) The SQL leaderboard patterns (what theyâ€™re training you to recognise)

### Player leaderboard view

They compute a score from raw events:

* score = 5 for `match_end`, else 1 for `player_elimination`
* group by `winner_player_id`
* rank by total score
* last_updated = max(timestamp)

Key SQL ideas:

* `CASE WHEN` inside `SUM()` to create weighted scoring
* `RANK() OVER (ORDER BY â€¦)` for leaderboard
* `MAX(timestamp)` for â€œlatest update timeâ€

### Team leaderboard view

* count match wins (`event_type='match_end'`)
* group by `winner_team_id`
* rank by `COUNT(*)`

**Exam cue:** If you see â€œleaderboardâ€, they love window functions (`RANK()`) and aggregation patterns.

---

# âœ… BigQuery module exam decision rules (memorise)

1. **Need ad-hoc analytics, unknown query patterns, massive scale** â†’ BigQuery
2. **Need low-latency serving reads for apps** â†’ Bigtable (BigQuery is not a serving DB)
3. **Need real-time ingestion into BigQuery with minimal processing** â†’ Pub/Sub â†’ BigQuery subscription (or Storage Write API)
4. **Need complex streaming transforms, state, late data correctness** â†’ Dataflow
5. **Need simple real-time SQL transforms and push results out** â†’ BigQuery continuous queries (requires reservations; stateless)
6. **Need scheduled loads from supported external systems** â†’ BigQuery DTS
7. **Need DB change stream including updates/deletes into BigQuery** â†’ CDC pattern
8. **Need to prevent accidental full scans on partitioned tables** â†’ `require_partition_filter`

---

If you paste the next module (Bigtable or Looker/serving layer), Iâ€™ll connect it directly to this one with a clean rule: **BigQuery for analytics vs Bigtable for serving**, and how Dataflow/continuous queries feed Bigtable.
